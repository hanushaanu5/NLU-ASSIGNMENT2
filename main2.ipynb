{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import spacy\n",
    "import re\n",
    "from spacy.tokens import Doc\n",
    "from collections import OrderedDict\n",
    "import operator\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing functions from file conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conll import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate spaCy NER on CoNLL 2003 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy2conllDict = {'PERSON':'PER', 'NORP':'MISC', 'LOC':'LOC', 'FAC':'LOC', 'GPE':'LOC', 'ORG':'ORG', 'PRODUCT':'MISC', 'EVENT':'MISC', 'WORK_OF_ART':'O', 'LAW':'O', 'LANGUAGE':'MISC', 'DATE':'O', 'TIME':'O', 'PERCENT':'O', 'MONEY':'O', 'QUANTITY':'O', 'ORDINAL':'O', 'CARDINAL':'O', '':'O'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatEntIob(iob, ent):\n",
    "    if spacy2conllDict[ent] == 'O':\n",
    "        return 'O'\n",
    "    else:\n",
    "        return iob + '-' + spacy2conllDict[ent]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading conll2003 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadConll2003:\n",
    "\n",
    "    def __init__(self, path_to_text):\n",
    "        self.sents = [] \n",
    "        self.txts = [] \n",
    "        self.jtxts = [] \n",
    "        lines = None\n",
    "        with open(path_to_text) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        lines = lines[2:] \n",
    "        sent = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if line != \"\\n\":\n",
    "                l = line.replace('\\n', '').split()\n",
    "                sent.append(tuple(l))\n",
    "            else:\n",
    "                self.sents.append(sent)\n",
    "                sent = []\n",
    "        \n",
    "        for sent in self.sents:\n",
    "            tsent = [list(el) for el in sent]\n",
    "            el = [s[0] for s in tsent]\n",
    "            self.txts.append(el)\n",
    "            self.jtxts.append(\" \".join(el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) <br> Report token-level performance (per class and total)\n",
    "\n",
    "    accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalAcc(dataSent, spaSent):\n",
    "    # creating variable\n",
    "    borgAccuracy,borgCorrect, borgError = 0, 0, 0\n",
    "    iorgAccuracy, iorgCorrect, iorgError = 0, 0, 0\n",
    "    blocAccuracy, blocCorrect, blocError = 0, 0, 0\n",
    "    ilocAccuracy, ilocCorrect, ilocError = 0, 0, 0\n",
    "    bmiscAccuracy, bmiscCorrect, bmiscError = 0, 0, 0\n",
    "    imiscAccuracy, imiscCorrect, imiscError = 0, 0, 0\n",
    "    bperAccuracy, bperCorrect, bperError = 0, 0, 0\n",
    "    iperAccuracy, iperCorrect, iperError = 0, 0, 0\n",
    "    oAccuracy, oCorrect, oError = 0, 0, 0\n",
    "    totAccuracy, totCorrect, totError = 0, 0, 0\n",
    "    \n",
    "    for cont in range(len(dataSent)):\n",
    "        for i, el in enumerate(dataSent[cont]):\n",
    "            if el[3] == spaSent[cont][i][1]:\n",
    "                totCorrect += 1\n",
    "                if el[3] == 'B-ORG':\n",
    "                    borgCorrect += 1\n",
    "                elif el[3] == 'I-ORG':\n",
    "                    iorgCorrect += 1\n",
    "                elif el[3] == 'B-MISC':\n",
    "                    bmiscCorrect += 1\n",
    "                elif el[3] == 'I-MISC':\n",
    "                    imiscCorrect += 1\n",
    "                elif el[3] == 'B-PER':\n",
    "                    bperCorrect += 1\n",
    "                elif el[3] == 'I-PER':\n",
    "                    iperCorrect += 1\n",
    "                elif el[3] == 'B-LOC':\n",
    "                    blocCorrect += 1\n",
    "                elif el[3] == 'I-LOC':\n",
    "                    ilocCorrect += 1\n",
    "                else:\n",
    "                    oCorrect += 1\n",
    "            else:\n",
    "                totError += 1\n",
    "                if el[3] == 'B-ORG':\n",
    "                    borgError += 1\n",
    "                elif el[3] == 'I-ORG':\n",
    "                    iorgError += 1\n",
    "                elif el[3] == 'B-MISC':\n",
    "                    bmiscError += 1\n",
    "                elif el[3] == 'I-MISC':\n",
    "                    imiscError += 1\n",
    "                elif el[3] == 'B-PER':\n",
    "                    bperError += 1\n",
    "                elif el[3] == 'I-PER':\n",
    "                    iperError += 1\n",
    "                elif el[3] == 'B-LOC':\n",
    "                    blocError += 1\n",
    "                elif el[3] == 'I-LOC':\n",
    "                    ilocError += 1\n",
    "                else:\n",
    "                    oError += 1\n",
    "\n",
    "    borgAccuracy = borgCorrect/(borgCorrect+borgError)\n",
    "    iorgAccuracy = iorgCorrect/(iorgCorrect+iorgError)\n",
    "\n",
    "    blocAccuracy = blocCorrect/(blocCorrect+blocError)\n",
    "    ilocAccuracy = ilocCorrect/(ilocCorrect+ilocError)\n",
    "\n",
    "    bmiscAccuracy = bmiscCorrect/(bmiscCorrect+bmiscError)\n",
    "    imiscAccuracy = imiscCorrect/(imiscCorrect+imiscError)\n",
    "\n",
    "    bperAccuracy = bperCorrect/(bperCorrect+bperError)\n",
    "    iperAccuracy = iperCorrect/(iperCorrect+iperError)\n",
    "\n",
    "    oAccuracy = oCorrect/(oCorrect+oError)\n",
    "\n",
    "    totAccuracy = totCorrect/(totCorrect+totError)\n",
    "\n",
    "    accuracy = {\n",
    "        'B-ORG': {'Accuracy': borgAccuracy}, 'I-ORG': {'Accuracy': iorgAccuracy}, \n",
    "        'B-LOC': {'Accuracy': blocAccuracy}, 'I-LOC': {'Accuracy': ilocAccuracy}, \n",
    "        'B-MISC': {'Accuracy': bmiscAccuracy}, 'I-MISC': {'Accuracy': imiscAccuracy},\n",
    "        'B-PER': {'Accuracy': bperAccuracy}, 'I-PER': {'Accuracy': bperAccuracy}, \n",
    "        'O': {'Accuracy': oAccuracy}, 'total': {'Accuracy': totAccuracy}\n",
    "    }\n",
    "\n",
    "    pd_tblAccuracy = pd.DataFrame().from_dict(accuracy, orient='index')\n",
    "    pd_tblAccuracy.round(decimals=3)\n",
    "    return pd_tblAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) <br> Report CoNLL chunk-level performance (per class and total)\n",
    "\n",
    "    precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conllEvaluation(conll2003, docs):\n",
    "    \n",
    "    refs = [[(text, iob) for text, x, y, iob in sent] for sent in conll2003.sents]\n",
    "    hyps = [[(text, iob) for text, iob in sent] for sent in docs]\n",
    "    results = evaluate(refs, hyps)\n",
    "\n",
    "    pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "    pd_tbl.round(decimals=3)\n",
    "    return pd_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenRectification(sent):\n",
    "    # Correction based on whitespace\n",
    "    new_sent = []\n",
    "    i = 0\n",
    "    while i < len(sent):\n",
    "        \n",
    "        el = [sent[i][0], sent[i][1]]\n",
    "        while sent[i][2] == '':\n",
    "            i += 1\n",
    "            if i == len(sent):\n",
    "                break\n",
    "            el[0] += sent[i][0]\n",
    "        new_sent.append(tuple(el))\n",
    "        i += 1\n",
    "    return new_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy2conll(docs):\n",
    "    hyps = []\n",
    "    for sent in docs:\n",
    "        mod_sent = []\n",
    "        for t in sent:\n",
    "            mod_sent.append((t.text, concatEntIob(t.ent_iob_, t.ent_type_), t.whitespace_))\n",
    "\n",
    "        c_sent = tokenRectification(mod_sent)\n",
    "        hyps.append(c_sent)\n",
    "    return hyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) <br> Grouping of Entities. Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupEntities(docs):\n",
    "\n",
    "    all_ents = []\n",
    "    for doc in docs:\n",
    "        doc_ents = []\n",
    "        for chunk in doc.noun_chunks:\n",
    "            chunk_ents = []\n",
    "            for cent in chunk.ents:\n",
    "                for ent in doc.ents:\n",
    "                    if cent == ent:\n",
    "                        chunk_ents.append(ent)\n",
    "            doc_ents.append(chunk_ents)\n",
    "\n",
    "        for ed in doc.ents:\n",
    "            ex = True\n",
    "            for a in doc_ents:\n",
    "                for b in a:\n",
    "                    if ed == b:\n",
    "                        ex = False  \n",
    "            if ex:\n",
    "                doc_ents.append([ed])   \n",
    "\n",
    "        ents = []\n",
    "        for ed in doc_ents:\n",
    "            chunk = []\n",
    "            for a in ed:\n",
    "                chunk.append(a.label_)\n",
    "            ents.append(chunk)\n",
    "        all_ents.append(ents)\n",
    "    return all_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statFreq(docs, n):\n",
    "    stats = {}\n",
    "    g_ents = groupEntities(docs)\n",
    "    for sent in g_ents:\n",
    "        for l in sent:\n",
    "            if tuple(l) in stats:\n",
    "                stats[tuple(l)] += 1\n",
    "            else:\n",
    "                stats[tuple(l)] = 1\n",
    "    stats.pop(())\n",
    "    sort = sorted(stats.items(),key=operator.itemgetter(1),reverse=True)[0:n]\n",
    "    dict_for_table = {}\n",
    "    for el in sort:\n",
    "        k = \"\"\n",
    "        for s in el[0]:\n",
    "            k = k+s+\"_\"\n",
    "        dict_for_table[k] = {'NoT': el[1]}\n",
    "\n",
    "\n",
    "    pd_tbl_freq = pd.DataFrame().from_dict(dict_for_table, orient='index')\n",
    "    pd_tbl_freq = pd_tbl_freq.sort_values(by=['NoT'], ascending=False)\n",
    "    pd_tbl_freq.round(decimals=3)\n",
    "    return pd_tbl_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) <br>One of the possible post-processing steps is to fix segmentation errors. Write a function that extends the entity span to cover the full noun-compounds. Make use of compound dependency relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compoundRectification(docs):\n",
    "    hyps = []\n",
    "    for sent in docs:\n",
    "        mod_sent = []\n",
    "        for t in sent:\n",
    "            if t.dep_ != 'compound' or t.ent_type_ != '':\n",
    "                mod_sent.append((t.text, concatEntIob(t.ent_iob_, t.ent_type_), t.whitespace_))\n",
    "            else:\n",
    "                if (t.head.i < t.i):\n",
    "                    mod_sent.append((t.text, concatEntIob('I', t.head.ent_type_), t.whitespace_))\n",
    "                else:\n",
    "                    mod_sent.append((t.text, concatEntIob('B', t.head.ent_type_), t.whitespace_))\n",
    "            \n",
    "        c_sent = tokenRectification(mod_sent)\n",
    "        hyps.append(c_sent)\n",
    "    return hyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = 'data/test.txt'\n",
    "\n",
    "conll2003 = ReadConll2003(PATH)\n",
    "docs = [nlp(sent) for sent in conll2003.jtxts]\n",
    "docs_corrected = spacy2conll(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) <br> Report token-level performance (per class and total)\n",
    "\n",
    "    accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token level accuracy: \n",
      "         Accuracy\n",
      "B-LOC   0.704436\n",
      "B-MISC  0.588319\n",
      "B-ORG   0.326911\n",
      "B-PER   0.603587\n",
      "I-LOC   0.595331\n",
      "I-MISC  0.425926\n",
      "I-ORG   0.548503\n",
      "I-PER   0.603587\n",
      "O       0.975436\n",
      "total   0.906397\n"
     ]
    }
   ],
   "source": [
    "# First Request - Part 1\n",
    "accuracy = CalAcc(conll2003.sents, docs_corrected)\n",
    "print('Token level accuracy: \\n', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) <br> Report CoNLL chunk-level performance (per class and total);\n",
    "\n",
    "    precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk level accuracy: \n",
      "               p         r         f     s\n",
      "ORG    0.445386  0.284768  0.347411  1661\n",
      "PER    0.688906  0.568336  0.622840  1617\n",
      "MISC   0.756144  0.569801  0.649878   702\n",
      "LOC    0.777554  0.693645  0.733207  1668\n",
      "total  0.668253  0.522132  0.586224  5648\n"
     ]
    }
   ],
   "source": [
    "# First Request - Part 2\n",
    "chunk_table = conllEvaluation(conll2003, docs_corrected)\n",
    "print('Chunk level accuracy: \\n', chunk_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) <br> Grouping of Entities. Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 20 : \n",
      "                    NoT\n",
      "CARDINAL_         1606\n",
      "GPE_              1281\n",
      "DATE_             1164\n",
      "PERSON_           1157\n",
      "ORG_               958\n",
      "NORP_              303\n",
      "MONEY_             151\n",
      "ORDINAL_           112\n",
      "TIME_               99\n",
      "PERCENT_            76\n",
      "QUANTITY_           76\n",
      "EVENT_              68\n",
      "LOC_                50\n",
      "NORP_PERSON_        45\n",
      "CARDINAL_PERSON_    31\n",
      "GPE_PERSON_         29\n",
      "ORG_PERSON_         28\n",
      "FAC_                26\n",
      "PRODUCT_            25\n",
      "CARDINAL_NORP_      14\n"
     ]
    }
   ],
   "source": [
    "N = 20\n",
    "best_n = statFreq(docs, N)\n",
    "print('Best', N, ': \\n', best_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) <br>One of the possible post-processing steps is to fix segmentation errors. Write a function that extends the entity span to cover the full noun-compounds. Make use of compound dependency relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Token level accuracy: \n",
      "         Accuracy\n",
      "B-LOC   0.704436\n",
      "B-MISC  0.589744\n",
      "B-ORG   0.328116\n",
      "B-PER   0.615337\n",
      "I-LOC   0.595331\n",
      "I-MISC  0.425926\n",
      "I-ORG   0.548503\n",
      "I-PER   0.615337\n",
      "O       0.969574\n",
      "total   0.902025\n"
     ]
    }
   ],
   "source": [
    "# Third request\n",
    "docs_compound_corr = compoundRectification(docs)\n",
    "\n",
    "new_accuracy = CalAcc(conll2003.sents, docs_compound_corr)\n",
    "print('New Token level accuracy: \\n', new_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New chunk level accuracy: \n",
      "               p         r         f     s\n",
      "ORG    0.431569  0.284768  0.343127  1661\n",
      "PER    0.597529  0.568336  0.582567  1617\n",
      "MISC   0.750469  0.569801  0.647773   702\n",
      "LOC    0.763193  0.693645  0.726759  1668\n",
      "total  0.629725  0.522132  0.570903  5648\n"
     ]
    }
   ],
   "source": [
    "new_chunk_table = conllEvaluation(conll2003, docs_compound_corr)\n",
    "print('New chunk level accuracy: \\n', new_chunk_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Thank You "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
